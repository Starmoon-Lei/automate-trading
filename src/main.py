# src/main.py
import asyncio
import logging
import sys
from datetime import datetime
from contextlib import asynccontextmanager
from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import signal
import gc
import psutil

from src.trading_engine import trading_engine
from src.models.database import db_manager
from src.config.settings import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)  # Railway.appæ—¥å¿—è¾“å‡º
    ]
)

logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
scheduler_task = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global scheduler_task

    # å¯åŠ¨é€»è¾‘
    logger.info("ğŸš€ Starting Free AI Trading System...")
    logger.info(f"ğŸ“Š Configuration: High confidence = {settings.HIGH_CONFIDENCE_THRESHOLD}")
    logger.info(f"ğŸ‘¥ Monitoring {len(settings.BLOGGER_IDS)} bloggers")
    logger.info(f"ğŸ’° OpenAI budget: ${settings.OPENAI_MONTHLY_BUDGET}/month")

    # å¯åŠ¨åå°è°ƒåº¦å™¨
    scheduler_task = asyncio.create_task(trading_engine.run_scheduler())

    # å‘é€å¯åŠ¨é€šçŸ¥
    try:
        from src.utils.email_service import email_service
        await email_service.send_system_alert(
            f"ğŸš€ å…è´¹AIäº¤æ˜“ç³»ç»Ÿå·²å¯åŠ¨\n\n"
            f"ğŸ“Š é…ç½®ä¿¡æ¯:\n"
            f"- é«˜ç½®ä¿¡åº¦é˜ˆå€¼: {settings.HIGH_CONFIDENCE_THRESHOLD}\n"
            f"- ç›‘æ§åšä¸»æ•°é‡: {len(settings.BLOGGER_IDS)}\n"
            f"- OpenAIé¢„ç®—: ${settings.OPENAI_MONTHLY_BUDGET}/æœˆ\n"
            f"- æ£€æŸ¥é—´éš”: {settings.CHECK_INTERVAL_MINUTES}åˆ†é’Ÿ\n\n"
            f"ç³»ç»Ÿå°†è‡ªåŠ¨ç›‘æ§ç¤¾åª’ä¿¡å·å¹¶å‘é€é‚®ä»¶é€šçŸ¥ï¼",
            "SUCCESS"
        )
    except Exception as e:
        logger.error(f"Failed to send startup notification: {e}")

    yield

    # å…³é—­é€»è¾‘
    logger.info("ğŸ›‘ Shutting down AI Trading System...")

    if scheduler_task:
        scheduler_task.cancel()
        try:
            await scheduler_task
        except asyncio.CancelledError:
            pass

    # å‘é€å…³é—­é€šçŸ¥
    try:
        from src.utils.email_service import email_service
        await email_service.send_system_alert("ğŸ›‘ AIäº¤æ˜“ç³»ç»Ÿå·²åœæ­¢", "INFO")
    except Exception as e:
        logger.error(f"Failed to send shutdown notification: {e}")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    lifespan=lifespan,
    title="Free AI Trading System",
    description="OpenAI + Supabase + Railway.app å…è´¹AIäº¤æ˜“ç³»ç»Ÿ",
    version="1.0.0"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "ğŸš€ Free AI Trading System is running!",
        "version": "1.0.0",
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        await db_manager.execute_query("SELECT 1")
        
        # æ£€æŸ¥AIè§£æå™¨çŠ¶æ€
        ai_stats = trading_engine.ai_parser.get_usage_stats()
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "memory_mb": round(memory_mb, 1),
            "memory_limit_mb": settings.MAX_MEMORY_MB,
            "openai_budget_used": f"{ai_stats['usage_percent']:.1f}%",
            "database": "connected"
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=500, detail=f"System unhealthy: {e}")

@app.get("/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡"""
    try:
        # ä»Šæ—¥ç»Ÿè®¡
        today = datetime.now().date()

        # ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢è·å–ä»Šæ—¥ä¿¡å·æ•°é‡
        today_signals_query = """
            SELECT COUNT(*) FROM ai_signals
            WHERE timestamp::date = $1
        """
        today_signals_result = await db_manager.execute_query(today_signals_query, today)
        today_signals = today_signals_result['count'] if today_signals_result else 0

        # é«˜ç½®ä¿¡åº¦ä¿¡å·æ•°é‡
        today_high_conf_query = """
            SELECT COUNT(*) FROM ai_signals
            WHERE timestamp::date = $1 AND confidence >= $2
        """
        today_high_conf_result = await db_manager.execute_query(
            today_high_conf_query, today, settings.HIGH_CONFIDENCE_THRESHOLD
        )
        today_high_conf = today_high_conf_result['count'] if today_high_conf_result else 0

        # ä»Šæ—¥äº¤æ˜“æ•°é‡
        today_trades_query = """
            SELECT COUNT(*) FROM trades
            WHERE timestamp::date = $1
        """
        today_trades_result = await db_manager.execute_query(today_trades_query, today)
        today_trades = today_trades_result['count'] if today_trades_result else 0

        # AIä½¿ç”¨ç»Ÿè®¡
        ai_stats = trading_engine.ai_parser.get_usage_stats()

        # å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        return {
            "today_stats": {
                "signals_generated": today_signals,
                "high_confidence_signals": today_high_conf,
                "trades_executed": today_trades
            },
            "ai_usage": {
                "monthly_cost": f"${ai_stats['monthly_usage']:.2f}",
                "budget_used": f"{ai_stats['usage_percent']:.1f}%",
                "remaining_budget": f"${ai_stats['remaining']:.2f}"
            },
            "system_status": {
                "memory_mb": round(memory_mb, 1),
                "memory_limit_mb": settings.MAX_MEMORY_MB,
                "uptime": "running"
            },
            "daily_stats": trading_engine.daily_stats
        }
        
    except Exception as e:
        logger.error(f"Failed to get stats: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get stats: {e}")

@app.get("/signals")
async def get_recent_signals(limit: int = 20):
    """è·å–æœ€è¿‘çš„ä¿¡å·"""
    try:
        # ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢è·å–æœ€è¿‘çš„ä¿¡å·
        signals_query = """
            SELECT id, symbol, action, confidence, target_price, reasoning,
                   risk_level, status, timestamp
            FROM ai_signals
            ORDER BY timestamp DESC
            LIMIT $1
        """

        signals_result = await db_manager.fetch_all(signals_query, limit)

        signals_list = []
        if signals_result:
            for signal in signals_result:
                reasoning = signal['reasoning']
                if reasoning and len(reasoning) > 100:
                    reasoning = reasoning[:100] + "..."

                signals_list.append({
                    "id": signal['id'],
                    "symbol": signal['symbol'],
                    "action": signal['action'],
                    "confidence": signal['confidence'],
                    "target_price": signal['target_price'],
                    "reasoning": reasoning,
                    "risk_level": signal['risk_level'],
                    "status": signal['status'],
                    "timestamp": signal['timestamp'].isoformat() if signal['timestamp'] else None
                })

        return {
            "signals": signals_list,
            "total": len(signals_list)
        }
        
    except Exception as e:
        logger.error(f"Failed to get signals: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get signals: {e}")

@app.get("/trades")
async def get_recent_trades(limit: int = 10):
    """è·å–æœ€è¿‘çš„äº¤æ˜“"""
    try:
        # ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢è·å–æœ€è¿‘çš„äº¤æ˜“
        trades_query = """
            SELECT id, symbol, action, quantity, entry_price, status, timestamp
            FROM trades
            ORDER BY timestamp DESC
            LIMIT $1
        """

        trades_result = await db_manager.fetch_all(trades_query, limit)

        trades_list = []
        if trades_result:
            for trade in trades_result:
                trades_list.append({
                    "id": trade['id'],
                    "symbol": trade['symbol'],
                    "action": trade['action'],
                    "quantity": trade['quantity'],
                    "entry_price": trade['entry_price'],
                    "status": trade['status'],
                    "timestamp": trade['timestamp'].isoformat() if trade['timestamp'] else None
                })

        return {
            "trades": trades_list,
            "total": len(trades_list)
        }
        
    except Exception as e:
        logger.error(f"Failed to get trades: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get trades: {e}")

@app.post("/trigger-check")
async def trigger_manual_check(background_tasks: BackgroundTasks):
    """æ‰‹åŠ¨è§¦å‘æ£€æŸ¥"""
    try:
        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(trading_engine.run_monitoring_cycle)
        
        return {
            "message": "Manual check triggered",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to trigger check: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to trigger check: {e}")

@app.post("/cleanup")
async def cleanup_system():
    """æ¸…ç†ç³»ç»Ÿèµ„æº"""
    try:
        # å†…å­˜æ¸…ç†
        trading_engine.cleanup_memory()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # è·å–æ¸…ç†åçš„å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        return {
            "message": "System cleanup completed",
            "memory_mb": round(memory_mb, 1),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to cleanup system: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to cleanup: {e}")

# é”™è¯¯å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    logger.error(f"Global exception: {exc}")
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )

# ä¿¡å·å¤„ç†
def signal_handler(signum, frame):
    """å¤„ç†åœæ­¢ä¿¡å·"""
    logger.info(f"Received signal {signum}, shutting down...")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

if __name__ == "__main__":
    # Railway.appä¼šè‡ªåŠ¨è®¾ç½®PORTç¯å¢ƒå˜é‡
    import os
    port = int(os.getenv("PORT", 8000))
    
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=port,
        log_level="info",
        access_log=True
    )